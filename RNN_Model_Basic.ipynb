{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bduh-46OHFK",
   "metadata": {
    "id": "3bduh-46OHFK"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "iUFDKHaVOHFN",
   "metadata": {
    "id": "iUFDKHaVOHFN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beLBhgRLOHFP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beLBhgRLOHFP",
    "outputId": "fe017141-8c90-4f18-d260-b91583d3e971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   _unit_id               8000 non-null   int64  \n",
      " 1   _golden                8000 non-null   bool   \n",
      " 2   _unit_state            8000 non-null   object \n",
      " 3   _trusted_judgments     8000 non-null   int64  \n",
      " 4   _last_judgment_at      8000 non-null   object \n",
      " 5   positivity             1420 non-null   float64\n",
      " 6   positivity:confidence  3775 non-null   float64\n",
      " 7   relevance              8000 non-null   object \n",
      " 8   relevance:confidence   8000 non-null   float64\n",
      " 9   articleid              8000 non-null   object \n",
      " 10  date                   8000 non-null   object \n",
      " 11  headline               8000 non-null   object \n",
      " 12  positivity_gold        0 non-null      float64\n",
      " 13  relevance_gold         0 non-null      float64\n",
      " 14  text                   8000 non-null   object \n",
      "dtypes: bool(1), float64(5), int64(2), object(7)\n",
      "memory usage: 882.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./US-Economic-News.csv\", delimiter=',', encoding= 'ISO-8859-1')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2pZ91v4YOHFQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "2pZ91v4YOHFQ",
    "outputId": "2ecb5bf5-5337-4d44-bf14-f45d0725524e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>positivity</th>\n",
       "      <th>positivity:confidence</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance:confidence</th>\n",
       "      <th>articleid</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>positivity_gold</th>\n",
       "      <th>relevance_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842613455</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398217788</td>\n",
       "      <td>8/14/91</td>\n",
       "      <td>Yields on CDs Fell in the Latest Week</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842613456</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 16:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_399019502</td>\n",
       "      <td>8/21/07</td>\n",
       "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Wall Street Journal Online&lt;/br&gt;&lt;/br&gt;The Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842613457</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 1:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_398284048</td>\n",
       "      <td>11/14/91</td>\n",
       "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>842613458</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 2:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.675</td>\n",
       "      <td>wsj_397959018</td>\n",
       "      <td>6/16/86</td>\n",
       "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>842613459</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398838054</td>\n",
       "      <td>10/4/02</td>\n",
       "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  842613455    False   finalized                   3     12/5/15 17:48   \n",
       "1  842613456    False   finalized                   3     12/5/15 16:54   \n",
       "2  842613457    False   finalized                   3      12/5/15 1:59   \n",
       "3  842613458    False   finalized                   3      12/5/15 2:19   \n",
       "4  842613459    False   finalized                   3     12/5/15 17:48   \n",
       "\n",
       "   positivity  positivity:confidence relevance  relevance:confidence  \\\n",
       "0         3.0                 0.6400       yes                 0.640   \n",
       "1         NaN                    NaN        no                 1.000   \n",
       "2         NaN                    NaN        no                 1.000   \n",
       "3         NaN                 0.0000        no                 0.675   \n",
       "4         3.0                 0.3257       yes                 0.640   \n",
       "\n",
       "       articleid      date                                           headline  \\\n",
       "0  wsj_398217788   8/14/91              Yields on CDs Fell in the Latest Week   \n",
       "1  wsj_399019502   8/21/07  The Morning Brief: White House Seeks to Limit ...   \n",
       "2  wsj_398284048  11/14/91  Banking Bill Negotiators Set Compromise --- Pl...   \n",
       "3  wsj_397959018   6/16/86  Manager's Journal: Sniffing Out Drug Abusers I...   \n",
       "4  wsj_398838054   10/4/02  Currency Trading: Dollar Remains in Tight Rang...   \n",
       "\n",
       "   positivity_gold  relevance_gold  \\\n",
       "0              NaN             NaN   \n",
       "1              NaN             NaN   \n",
       "2              NaN             NaN   \n",
       "3              NaN             NaN   \n",
       "4              NaN             NaN   \n",
       "\n",
       "                                                text  \n",
       "0  NEW YORK -- Yields on most certificates of dep...  \n",
       "1  The Wall Street Journal Online</br></br>The Mo...  \n",
       "2  WASHINGTON -- In an effort to achieve banking ...  \n",
       "3  The statistics on the enormous costs of employ...  \n",
       "4  NEW YORK -- Indecision marked the dollar's ton...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfFHenMOHFQ",
   "metadata": {
    "id": "6dfFHenMOHFQ"
   },
   "outputs": [],
   "source": [
    "df = df[['headline', 'text', 'relevance']]\n",
    "\n",
    "# We drop all irrelavant features to only keep headline and text for 2 reasons: \n",
    "# The other features seem either irrelevant or we lack documentation\n",
    "# With headline and text only, our final model will be more generalizable. We could in theory apply it to any article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oRrzx8WvOHFR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oRrzx8WvOHFR",
    "outputId": "7b9c6dd5-8a57-47a0-9c63-72bac3ab1bea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yields on CDs Fell in the Latest Week</td>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
       "      <td>The Wall Street Journal Online&lt;/br&gt;&lt;/br&gt;The Mo...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0              Yields on CDs Fell in the Latest Week   \n",
       "1  The Morning Brief: White House Seeks to Limit ...   \n",
       "2  Banking Bill Negotiators Set Compromise --- Pl...   \n",
       "3  Manager's Journal: Sniffing Out Drug Abusers I...   \n",
       "4  Currency Trading: Dollar Remains in Tight Rang...   \n",
       "\n",
       "                                                text relevance  \n",
       "0  NEW YORK -- Yields on most certificates of dep...       yes  \n",
       "1  The Wall Street Journal Online</br></br>The Mo...        no  \n",
       "2  WASHINGTON -- In an effort to achieve banking ...        no  \n",
       "3  The statistics on the enormous costs of employ...        no  \n",
       "4  NEW YORK -- Indecision marked the dollar's ton...       yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jK-dXnQAOHFR",
   "metadata": {
    "id": "jK-dXnQAOHFR"
   },
   "source": [
    "Cleaning Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "kS0pN2EEOHFS",
   "metadata": {
    "id": "kS0pN2EEOHFS"
   },
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fpS1zR46OHFS",
   "metadata": {
    "id": "fpS1zR46OHFS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "T8bYfqW0OHFS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8bYfqW0OHFS",
    "outputId": "0e457b24-c049-4984-ed6b-29f344f613b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\majon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\majon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\majon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Ensure you have downloaded the necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hwsu0fkMOHFS",
   "metadata": {
    "id": "hwsu0fkMOHFS"
   },
   "outputs": [],
   "source": [
    "df['whole_txt'] = df['headline']+ ' ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tGK5t8RyOHFT",
   "metadata": {
    "id": "tGK5t8RyOHFT"
   },
   "outputs": [],
   "source": [
    "wtxt_train = np.array(df['whole_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "kPJu-IuxOHFT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPJu-IuxOHFT",
    "outputId": "38626369-0963-40be-8d89-321e151d7b9b"
   },
   "outputs": [],
   "source": [
    "#print(wtxt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8EX1KU3FOHFT",
   "metadata": {
    "id": "8EX1KU3FOHFT"
   },
   "outputs": [],
   "source": [
    "for i in range(len(wtxt_train)):\n",
    "    # Taking out '<br>' in the 'whole_text' column\n",
    "    wtxt_train[i] = re.sub(r'</?br>', ' ', wtxt_train[i])\n",
    "    # Deletion of non-latin alfabet signs, also numbers\n",
    "    wtxt_train[i] = re.sub(r'[^a-zA-Z]', ' ', wtxt_train[i])\n",
    "    # Removing single letter works like 'a'.\n",
    "    wtxt_train[i] = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', wtxt_train[i])\n",
    "    # Removing double spaces\n",
    "    wtxt_train[i] = re.sub(r'\\s+', ' ', wtxt_train[i])\n",
    "    # Lower case\n",
    "    wtxt_train[i] = wtxt_train[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OGok8jBiOHFT",
   "metadata": {
    "id": "OGok8jBiOHFT"
   },
   "source": [
    "Split the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "YLC_hbBPOHFT",
   "metadata": {
    "id": "YLC_hbBPOHFT"
   },
   "outputs": [],
   "source": [
    "for i in range(len(wtxt_train)):\n",
    "    wtxt_train[i] = word_tokenize(wtxt_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nJcjnqLHOHFT",
   "metadata": {
    "id": "nJcjnqLHOHFT"
   },
   "source": [
    "Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7uoaH6INOHFT",
   "metadata": {
    "id": "7uoaH6INOHFT"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(wtxt_train)):\n",
    "    wtxt_train[i] = [word for word in wtxt_train[i] if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74Ii4vxnOHFU",
   "metadata": {
    "id": "74Ii4vxnOHFU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yields',\n",
       " 'cds',\n",
       " 'fell',\n",
       " 'latest',\n",
       " 'week',\n",
       " 'new',\n",
       " 'york',\n",
       " 'yields',\n",
       " 'certificates',\n",
       " 'deposit',\n",
       " 'offered',\n",
       " 'major',\n",
       " 'banks',\n",
       " 'dropped',\n",
       " 'tenth',\n",
       " 'percentage',\n",
       " 'point',\n",
       " 'latest',\n",
       " 'week',\n",
       " 'reflecting',\n",
       " 'overall',\n",
       " 'decline',\n",
       " 'short',\n",
       " 'term',\n",
       " 'interest',\n",
       " 'rates',\n",
       " 'small',\n",
       " 'denomination',\n",
       " 'consumer',\n",
       " 'cds',\n",
       " 'sold',\n",
       " 'directly',\n",
       " 'banks',\n",
       " 'average',\n",
       " 'yield',\n",
       " 'six',\n",
       " 'month',\n",
       " 'deposits',\n",
       " 'fell',\n",
       " 'week',\n",
       " 'ended',\n",
       " 'yesterday',\n",
       " 'according',\n",
       " 'bank',\n",
       " 'survey',\n",
       " 'banxquote',\n",
       " 'money',\n",
       " 'markets',\n",
       " 'wilmington',\n",
       " 'del',\n",
       " 'information',\n",
       " 'service',\n",
       " 'three',\n",
       " 'month',\n",
       " 'consumer',\n",
       " 'deposits',\n",
       " 'average',\n",
       " 'yield',\n",
       " 'sank',\n",
       " 'week',\n",
       " 'according',\n",
       " 'banxquote',\n",
       " 'two',\n",
       " 'banks',\n",
       " 'banxquote',\n",
       " 'survey',\n",
       " 'citibank',\n",
       " 'new',\n",
       " 'york',\n",
       " 'corestates',\n",
       " 'pennsylvania',\n",
       " 'paying',\n",
       " 'less',\n",
       " 'threemonth',\n",
       " 'small',\n",
       " 'denomination',\n",
       " 'cds',\n",
       " 'declines',\n",
       " 'somewhat',\n",
       " 'smaller',\n",
       " 'five',\n",
       " 'year',\n",
       " 'consumer',\n",
       " 'cds',\n",
       " 'eased',\n",
       " 'banxquote',\n",
       " 'said',\n",
       " 'yields',\n",
       " 'three',\n",
       " 'month',\n",
       " 'six',\n",
       " 'month',\n",
       " 'treasury',\n",
       " 'bills',\n",
       " 'sold',\n",
       " 'monday',\n",
       " 'auction',\n",
       " 'plummeted',\n",
       " 'fifth',\n",
       " 'percentage',\n",
       " 'point',\n",
       " 'previous',\n",
       " 'week',\n",
       " 'respectively']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtxt_train[0]\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0Ih9nJCDOHFU",
   "metadata": {
    "id": "0Ih9nJCDOHFU"
   },
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tZq0soQFOHFU",
   "metadata": {
    "id": "tZq0soQFOHFU"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(wtxt_train)):\n",
    "    wtxt_train[i] = [lemmatizer.lemmatize(word) for word in wtxt_train[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "yh7EcIK7OHFU",
   "metadata": {
    "id": "yh7EcIK7OHFU"
   },
   "outputs": [],
   "source": [
    "df['whole_txt'] = wtxt_train\n",
    "df = df.drop(['headline', 'text'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "T1TLLZZhOHFU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T1TLLZZhOHFU",
    "outputId": "127d4d92-3e49-4449-8bff-a5ab1fa375cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>whole_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>[yield, cd, fell, latest, week, new, york, yie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>[morning, brief, white, house, seek, limit, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>[banking, bill, negotiator, set, compromise, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>[manager, journal, sniffing, drug, abuser, qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>[currency, trading, dollar, remains, tight, ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relevance                                          whole_txt\n",
       "0       yes  [yield, cd, fell, latest, week, new, york, yie...\n",
       "1        no  [morning, brief, white, house, seek, limit, ch...\n",
       "2        no  [banking, bill, negotiator, set, compromise, p...\n",
       "3        no  [manager, journal, sniffing, drug, abuser, qui...\n",
       "4       yes  [currency, trading, dollar, remains, tight, ra..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e868e34",
   "metadata": {
    "id": "1e868e34"
   },
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ecc91",
   "metadata": {
    "id": "2a9ecc91"
   },
   "source": [
    "### Data preparation\n",
    "* Initial Data Processing: Our first step is to encode the relevance label into both the Relevant (1) and non-Relevant labels (0). Then, we make it into a np.array to feed into the model.\n",
    "* Then, we begin to clean text data into pad sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d046d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(df[\"relevance\"].apply(lambda x: 0 if x == \"no\" else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c64fe00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>whole_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[yield, cd, fell, latest, week, new, york, yie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[morning, brief, white, house, seek, limit, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[banking, bill, negotiator, set, compromise, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[manager, journal, sniffing, drug, abuser, qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[currency, trading, dollar, remains, tight, ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relevance                                          whole_txt\n",
       "0         1  [yield, cd, fell, latest, week, new, york, yie...\n",
       "1         0  [morning, brief, white, house, seek, limit, ch...\n",
       "2         0  [banking, bill, negotiator, set, compromise, p...\n",
       "3         0  [manager, journal, sniffing, drug, abuser, qui...\n",
       "4         1  [currency, trading, dollar, remains, tight, ra..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc686094",
   "metadata": {
    "id": "bc686094"
   },
   "source": [
    "### Tokenization\n",
    "First, we need to \"tokenize\" our sentences, i.e., convert them to sequences of numbers. For this task, we are going to use the `Tokenizer` from Tensorflow (documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf9eaddf",
   "metadata": {
    "id": "cf9eaddf"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(wtxt_train)   # fit our tokenizer on the dataset (i.e., assign a number to each word and keep a\n",
    "                                    # dictionary with the correspondence of each word to a number)\n",
    "\n",
    "# see the language dictionary and the total number of words (please note that number 0 is reserved for the padding task)\n",
    "word_index = tokenizer.word_index\n",
    "total_words = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bb124ce",
   "metadata": {
    "id": "1bb124ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 1,\n",
       " 'market': 2,\n",
       " 'said': 3,\n",
       " 'rate': 4,\n",
       " 'stock': 5,\n",
       " 'new': 6,\n",
       " 'price': 7,\n",
       " 'would': 8,\n",
       " 'economy': 9,\n",
       " 'bank': 10,\n",
       " 'economic': 11,\n",
       " 'percent': 12,\n",
       " 'interest': 13,\n",
       " 'federal': 14,\n",
       " 'last': 15,\n",
       " 'month': 16,\n",
       " 'company': 17,\n",
       " 'billion': 18,\n",
       " 'week': 19,\n",
       " 'one': 20,\n",
       " 'inflation': 21,\n",
       " 'million': 22,\n",
       " 'investor': 23,\n",
       " 'fed': 24,\n",
       " 'point': 25,\n",
       " 'dollar': 26,\n",
       " 'time': 27,\n",
       " 'bond': 28,\n",
       " 'tax': 29,\n",
       " 'government': 30,\n",
       " 'president': 31,\n",
       " 'first': 32,\n",
       " 'york': 33,\n",
       " 'say': 34,\n",
       " 'growth': 35,\n",
       " 'fund': 36,\n",
       " 'day': 37,\n",
       " 'increase': 38,\n",
       " 'yesterday': 39,\n",
       " 'reserve': 40,\n",
       " 'share': 41,\n",
       " 'also': 42,\n",
       " 'business': 43,\n",
       " 'average': 44,\n",
       " 'since': 45,\n",
       " 'two': 46,\n",
       " 'may': 47,\n",
       " 'many': 48,\n",
       " 'state': 49,\n",
       " 'index': 50,\n",
       " 'could': 51,\n",
       " 'high': 52,\n",
       " 'quarter': 53,\n",
       " 'money': 54,\n",
       " 'report': 55,\n",
       " 'mr': 56,\n",
       " 'job': 57,\n",
       " 'trading': 58,\n",
       " 'cut': 59,\n",
       " 'financial': 60,\n",
       " 'rose': 61,\n",
       " 'deficit': 62,\n",
       " 'consumer': 63,\n",
       " 'sale': 64,\n",
       " 'gain': 65,\n",
       " 'higher': 66,\n",
       " 'dow': 67,\n",
       " 'policy': 68,\n",
       " 'even': 69,\n",
       " 'budget': 70,\n",
       " 'economist': 71,\n",
       " 'american': 72,\n",
       " 'analyst': 73,\n",
       " 'much': 74,\n",
       " 'term': 75,\n",
       " 'trade': 76,\n",
       " 'treasury': 77,\n",
       " 'today': 78,\n",
       " 'spending': 79,\n",
       " 'people': 80,\n",
       " 'recession': 81,\n",
       " 'cost': 82,\n",
       " 'security': 83,\n",
       " 'rise': 84,\n",
       " 'plan': 85,\n",
       " 'decline': 86,\n",
       " 'house': 87,\n",
       " 'fell': 88,\n",
       " 'washington': 89,\n",
       " 'good': 90,\n",
       " 'level': 91,\n",
       " 'cent': 92,\n",
       " 'low': 93,\n",
       " 'three': 94,\n",
       " 'official': 95,\n",
       " 'exchange': 96,\n",
       " 'unemployment': 97,\n",
       " 'investment': 98,\n",
       " 'nation': 99,\n",
       " 'home': 100,\n",
       " 'long': 101,\n",
       " 'world': 102,\n",
       " 'make': 103,\n",
       " 'lower': 104,\n",
       " 'credit': 105,\n",
       " 'loan': 106,\n",
       " 'still': 107,\n",
       " 'department': 108,\n",
       " 'industry': 109,\n",
       " 'issue': 110,\n",
       " 'expected': 111,\n",
       " 'country': 112,\n",
       " 'industrial': 113,\n",
       " 'next': 114,\n",
       " 'recent': 115,\n",
       " 'back': 116,\n",
       " 'board': 117,\n",
       " 'end': 118,\n",
       " 'big': 119,\n",
       " 'chairman': 120,\n",
       " 'income': 121,\n",
       " 'record': 122,\n",
       " 'past': 123,\n",
       " 'labor': 124,\n",
       " 'news': 125,\n",
       " 'firm': 126,\n",
       " 'number': 127,\n",
       " 'service': 128,\n",
       " 'program': 129,\n",
       " 'jones': 130,\n",
       " 'profit': 131,\n",
       " 'administration': 132,\n",
       " 'according': 133,\n",
       " 'way': 134,\n",
       " 'street': 135,\n",
       " 'group': 136,\n",
       " 'national': 137,\n",
       " 'mortgage': 138,\n",
       " 'le': 139,\n",
       " 'well': 140,\n",
       " 'get': 141,\n",
       " 'like': 142,\n",
       " 'oil': 143,\n",
       " 'worker': 144,\n",
       " 'per': 145,\n",
       " 'bill': 146,\n",
       " 'major': 147,\n",
       " 'inc': 148,\n",
       " 'work': 149,\n",
       " 'loss': 150,\n",
       " 'second': 151,\n",
       " 'debt': 152,\n",
       " 'wall': 153,\n",
       " 'chief': 154,\n",
       " 'late': 155,\n",
       " 'short': 156,\n",
       " 'congress': 157,\n",
       " 'currency': 158,\n",
       " 'move': 159,\n",
       " 'change': 160,\n",
       " 'pay': 161,\n",
       " 'take': 162,\n",
       " 'system': 163,\n",
       " 'strong': 164,\n",
       " 'early': 165,\n",
       " 'future': 166,\n",
       " 'recovery': 167,\n",
       " 'another': 168,\n",
       " 'made': 169,\n",
       " 'part': 170,\n",
       " 'data': 171,\n",
       " 'close': 172,\n",
       " 'fall': 173,\n",
       " 'bush': 174,\n",
       " 'reported': 175,\n",
       " 'problem': 176,\n",
       " 'central': 177,\n",
       " 'capital': 178,\n",
       " 'earlier': 179,\n",
       " 'drop': 180,\n",
       " 'corp': 181,\n",
       " 'come': 182,\n",
       " 'co': 183,\n",
       " 'friday': 184,\n",
       " 'earnings': 185,\n",
       " 'yield': 186,\n",
       " 'among': 187,\n",
       " 'public': 188,\n",
       " 'rising': 189,\n",
       " 'see': 190,\n",
       " 'real': 191,\n",
       " 'nasdaq': 192,\n",
       " 'small': 193,\n",
       " 'little': 194,\n",
       " 'figure': 195,\n",
       " 'committee': 196,\n",
       " 'foreign': 197,\n",
       " 'third': 198,\n",
       " 'executive': 199,\n",
       " 'result': 200,\n",
       " 'ago': 201,\n",
       " 'raise': 202,\n",
       " 'help': 203,\n",
       " 'annual': 204,\n",
       " 'half': 205,\n",
       " 'nearly': 206,\n",
       " 'u': 207,\n",
       " 'go': 208,\n",
       " 'far': 209,\n",
       " 'value': 210,\n",
       " 'show': 211,\n",
       " 'based': 212,\n",
       " 'likely': 213,\n",
       " 'demand': 214,\n",
       " 'put': 215,\n",
       " 'city': 216,\n",
       " 'standard': 217,\n",
       " 'however': 218,\n",
       " 'global': 219,\n",
       " 'might': 220,\n",
       " 'june': 221,\n",
       " 'july': 222,\n",
       " 'product': 223,\n",
       " 'set': 224,\n",
       " 'keep': 225,\n",
       " 'international': 226,\n",
       " 'rally': 227,\n",
       " 'need': 228,\n",
       " 'sign': 229,\n",
       " 'four': 230,\n",
       " 'current': 231,\n",
       " 'trader': 232,\n",
       " 'japan': 233,\n",
       " 'housing': 234,\n",
       " 'area': 235,\n",
       " 'concern': 236,\n",
       " 'march': 237,\n",
       " 'buy': 238,\n",
       " 'meeting': 239,\n",
       " 'united': 240,\n",
       " 'office': 241,\n",
       " 'corporate': 242,\n",
       " 'benefit': 243,\n",
       " 'crisis': 244,\n",
       " 'better': 245,\n",
       " 'fiscal': 246,\n",
       " 'five': 247,\n",
       " 'large': 248,\n",
       " 'january': 249,\n",
       " 'session': 250,\n",
       " 'including': 251,\n",
       " 'deal': 252,\n",
       " 'several': 253,\n",
       " 'member': 254,\n",
       " 'going': 255,\n",
       " 'period': 256,\n",
       " 'measure': 257,\n",
       " 'general': 258,\n",
       " 'risk': 259,\n",
       " 'think': 260,\n",
       " 'april': 261,\n",
       " 'poor': 262,\n",
       " 'white': 263,\n",
       " 'political': 264,\n",
       " 'manager': 265,\n",
       " 'right': 266,\n",
       " 'largest': 267,\n",
       " 'volume': 268,\n",
       " 'america': 269,\n",
       " 'tuesday': 270,\n",
       " 'hit': 271,\n",
       " 'senate': 272,\n",
       " 'despite': 273,\n",
       " 'fear': 274,\n",
       " 'revenue': 275,\n",
       " 'health': 276,\n",
       " 'around': 277,\n",
       " 'republican': 278,\n",
       " 'start': 279,\n",
       " 'increased': 280,\n",
       " 'least': 281,\n",
       " 'compared': 282,\n",
       " 'sector': 283,\n",
       " 'thing': 284,\n",
       " 'whether': 285,\n",
       " 'greenspan': 286,\n",
       " 'buying': 287,\n",
       " 'already': 288,\n",
       " 'monday': 289,\n",
       " 'finance': 290,\n",
       " 'continued': 291,\n",
       " 'enough': 292,\n",
       " 'six': 293,\n",
       " 'ahead': 294,\n",
       " 'pressure': 295,\n",
       " 'though': 296,\n",
       " 'forecast': 297,\n",
       " 'top': 298,\n",
       " 'wage': 299,\n",
       " 'want': 300,\n",
       " 'employment': 301,\n",
       " 'return': 302,\n",
       " 'biggest': 303,\n",
       " 'sell': 304,\n",
       " 'monetary': 305,\n",
       " 'china': 306,\n",
       " 'order': 307,\n",
       " 'mean': 308,\n",
       " 'look': 309,\n",
       " 'technology': 310,\n",
       " 'called': 311,\n",
       " 'yen': 312,\n",
       " 'private': 313,\n",
       " 'came': 314,\n",
       " 'without': 315,\n",
       " 'wednesday': 316,\n",
       " 'making': 317,\n",
       " 'growing': 318,\n",
       " 'effort': 319,\n",
       " 'action': 320,\n",
       " 'ended': 321,\n",
       " 'best': 322,\n",
       " 'continue': 323,\n",
       " 'law': 324,\n",
       " 'run': 325,\n",
       " 'leader': 326,\n",
       " 'management': 327,\n",
       " 'began': 328,\n",
       " 'closed': 329,\n",
       " 'thursday': 330,\n",
       " 'clinton': 331,\n",
       " 'proposal': 332,\n",
       " 'war': 333,\n",
       " 'insurance': 334,\n",
       " 'force': 335,\n",
       " 'call': 336,\n",
       " 'added': 337,\n",
       " 'post': 338,\n",
       " 'total': 339,\n",
       " 'reagan': 340,\n",
       " 'although': 341,\n",
       " 'mark': 342,\n",
       " 'selling': 343,\n",
       " 'almost': 344,\n",
       " 'yet': 345,\n",
       " 'latest': 346,\n",
       " 'face': 347,\n",
       " 'saving': 348,\n",
       " 'survey': 349,\n",
       " 'county': 350,\n",
       " 'advance': 351,\n",
       " 'effect': 352,\n",
       " 'asset': 353,\n",
       " 'lost': 354,\n",
       " 'support': 355,\n",
       " 'sharply': 356,\n",
       " 'employee': 357,\n",
       " 'question': 358,\n",
       " 'director': 359,\n",
       " 'old': 360,\n",
       " 'hour': 361,\n",
       " 'account': 362,\n",
       " 'control': 363,\n",
       " 'supply': 364,\n",
       " 'boost': 365,\n",
       " 'cash': 366,\n",
       " 'every': 367,\n",
       " 'give': 368,\n",
       " 'european': 369,\n",
       " 'percentage': 370,\n",
       " 'become': 371,\n",
       " 'union': 372,\n",
       " 'dropped': 373,\n",
       " 'pace': 374,\n",
       " 'commerce': 375,\n",
       " 'offer': 376,\n",
       " 'europe': 377,\n",
       " 'taking': 378,\n",
       " 'banking': 379,\n",
       " 'activity': 380,\n",
       " 'previous': 381,\n",
       " 'energy': 382,\n",
       " 'decade': 383,\n",
       " 'told': 384,\n",
       " 'october': 385,\n",
       " 'social': 386,\n",
       " 'power': 387,\n",
       " 'line': 388,\n",
       " 'took': 389,\n",
       " 'case': 390,\n",
       " 'japanese': 391,\n",
       " 'maker': 392,\n",
       " 'democrat': 393,\n",
       " 'declined': 394,\n",
       " 'school': 395,\n",
       " 'export': 396,\n",
       " 'estimate': 397,\n",
       " 'showed': 398,\n",
       " 'gold': 399,\n",
       " 'domestic': 400,\n",
       " 'key': 401,\n",
       " 'december': 402,\n",
       " 'slightly': 403,\n",
       " 'august': 404,\n",
       " 'hope': 405,\n",
       " 'secretary': 406,\n",
       " 'care': 407,\n",
       " 'euro': 408,\n",
       " 'fourth': 409,\n",
       " 'composite': 410,\n",
       " 'rule': 411,\n",
       " 'family': 412,\n",
       " 'note': 413,\n",
       " 'agency': 414,\n",
       " 'food': 415,\n",
       " 'november': 416,\n",
       " 'production': 417,\n",
       " 'research': 418,\n",
       " 'blue': 419,\n",
       " 'september': 420,\n",
       " 'expect': 421,\n",
       " 'decision': 422,\n",
       " 'must': 423,\n",
       " 'chip': 424,\n",
       " 'expectation': 425,\n",
       " 'amount': 426,\n",
       " 'net': 427,\n",
       " 'association': 428,\n",
       " 'coming': 429,\n",
       " 'find': 430,\n",
       " 'highest': 431,\n",
       " 'view': 432,\n",
       " 'auto': 433,\n",
       " 'reason': 434,\n",
       " 'outlook': 435,\n",
       " 'local': 436,\n",
       " 'place': 437,\n",
       " 'open': 438,\n",
       " 'former': 439,\n",
       " 'february': 440,\n",
       " 'later': 441,\n",
       " 'productivity': 442,\n",
       " 'lowest': 443,\n",
       " 'contract': 444,\n",
       " 'retail': 445,\n",
       " 'head': 446,\n",
       " 'payment': 447,\n",
       " 'vice': 448,\n",
       " 'full': 449,\n",
       " 'near': 450,\n",
       " 'estate': 451,\n",
       " 'soon': 452,\n",
       " 'know': 453,\n",
       " 'campaign': 454,\n",
       " 'option': 455,\n",
       " 'hold': 456,\n",
       " 'steel': 457,\n",
       " 'fact': 458,\n",
       " 'commission': 459,\n",
       " 'important': 460,\n",
       " 'election': 461,\n",
       " 'seen': 462,\n",
       " 'lot': 463,\n",
       " 'sharp': 464,\n",
       " 'bad': 465,\n",
       " 'lead': 466,\n",
       " 'unit': 467,\n",
       " 'announced': 468,\n",
       " 'university': 469,\n",
       " 'used': 470,\n",
       " 'worry': 471,\n",
       " 'released': 472,\n",
       " 'computer': 473,\n",
       " 'recently': 474,\n",
       " 'believe': 475,\n",
       " 'institution': 476,\n",
       " 'helped': 477,\n",
       " 'toward': 478,\n",
       " 'performance': 479,\n",
       " 'equity': 480,\n",
       " 'store': 481,\n",
       " 'left': 482,\n",
       " 'car': 483,\n",
       " 'charge': 484,\n",
       " 'life': 485,\n",
       " 'reduce': 486,\n",
       " 'weak': 487,\n",
       " 'falling': 488,\n",
       " 'away': 489,\n",
       " 'confidence': 490,\n",
       " 'manufacturing': 491,\n",
       " 'congressional': 492,\n",
       " 'summer': 493,\n",
       " 'use': 494,\n",
       " 'district': 495,\n",
       " 'led': 496,\n",
       " 'hard': 497,\n",
       " 'purchase': 498,\n",
       " 'longer': 499,\n",
       " 'turn': 500,\n",
       " 'slow': 501,\n",
       " 'study': 502,\n",
       " 'talk': 503,\n",
       " 'card': 504,\n",
       " 'senior': 505,\n",
       " 'jobless': 506,\n",
       " 'holding': 507,\n",
       " 'overall': 508,\n",
       " 'held': 509,\n",
       " 'indicator': 510,\n",
       " 'import': 511,\n",
       " 'great': 512,\n",
       " 'following': 513,\n",
       " 'vote': 514,\n",
       " 'council': 515,\n",
       " 'statement': 516,\n",
       " 'seven': 517,\n",
       " 'reduction': 518,\n",
       " 'often': 519,\n",
       " 'amid': 520,\n",
       " 'robert': 521,\n",
       " 'individual': 522,\n",
       " 'target': 523,\n",
       " 'democratic': 524,\n",
       " 'industrials': 525,\n",
       " 'defense': 526,\n",
       " 'remain': 527,\n",
       " 'looking': 528,\n",
       " 'hand': 529,\n",
       " 'p': 530,\n",
       " 'john': 531,\n",
       " 'banker': 532,\n",
       " 'found': 533,\n",
       " 'leading': 534,\n",
       " 'development': 535,\n",
       " 'instead': 536,\n",
       " 'trend': 537,\n",
       " 'strength': 538,\n",
       " 'party': 539,\n",
       " 'course': 540,\n",
       " 'expansion': 541,\n",
       " 'step': 542,\n",
       " 'raising': 543,\n",
       " 'lending': 544,\n",
       " 'mixed': 545,\n",
       " 'rather': 546,\n",
       " 'mutual': 547,\n",
       " 'personal': 548,\n",
       " 'agreement': 549,\n",
       " 'gained': 550,\n",
       " 'monthly': 551,\n",
       " 'gross': 552,\n",
       " 'others': 553,\n",
       " 'due': 554,\n",
       " 'conference': 555,\n",
       " 'buyer': 556,\n",
       " 'adjusted': 557,\n",
       " 'push': 558,\n",
       " 'surge': 559,\n",
       " 'position': 560,\n",
       " 'customer': 561,\n",
       " 'obama': 562,\n",
       " 'region': 563,\n",
       " 'building': 564,\n",
       " 'sold': 565,\n",
       " 'impact': 566,\n",
       " 'factor': 567,\n",
       " 'raised': 568,\n",
       " 'begin': 569,\n",
       " 'provide': 570,\n",
       " 'fixed': 571,\n",
       " 'operation': 572,\n",
       " 'proposed': 573,\n",
       " 'aid': 574,\n",
       " 'condition': 575,\n",
       " 'getting': 576,\n",
       " 'within': 577,\n",
       " 'free': 578,\n",
       " 'output': 579,\n",
       " 'got': 580,\n",
       " 'traded': 581,\n",
       " 'black': 582,\n",
       " 'possible': 583,\n",
       " 'known': 584,\n",
       " 'example': 585,\n",
       " 'list': 586,\n",
       " 'given': 587,\n",
       " 'claim': 588,\n",
       " 'west': 589,\n",
       " 'balance': 590,\n",
       " 'ever': 591,\n",
       " 'regulator': 592,\n",
       " 'evidence': 593,\n",
       " 'retailer': 594,\n",
       " 'lender': 595,\n",
       " 'along': 596,\n",
       " 'motor': 597,\n",
       " 'especially': 598,\n",
       " 'history': 599,\n",
       " 'center': 600,\n",
       " 'comment': 601,\n",
       " 'offering': 602,\n",
       " 'across': 603,\n",
       " 'strategy': 604,\n",
       " 'slowdown': 605,\n",
       " 'final': 606,\n",
       " 'seems': 607,\n",
       " 'reform': 608,\n",
       " 'commodity': 609,\n",
       " 'range': 610,\n",
       " 'alan': 611,\n",
       " 'bernanke': 612,\n",
       " 'probably': 613,\n",
       " 'remains': 614,\n",
       " 'trillion': 615,\n",
       " 'mid': 616,\n",
       " 'reached': 617,\n",
       " 'matter': 618,\n",
       " 'meet': 619,\n",
       " 'college': 620,\n",
       " 'c': 621,\n",
       " 'taken': 622,\n",
       " 'living': 623,\n",
       " 'broad': 624,\n",
       " 'act': 625,\n",
       " 'idea': 626,\n",
       " 'generally': 627,\n",
       " 'discount': 628,\n",
       " 'middle': 629,\n",
       " 'portfolio': 630,\n",
       " 'information': 631,\n",
       " 'significant': 632,\n",
       " 'side': 633,\n",
       " 'prospect': 634,\n",
       " 'adviser': 635,\n",
       " 'clear': 636,\n",
       " 'press': 637,\n",
       " 'limit': 638,\n",
       " 'community': 639,\n",
       " 'fee': 640,\n",
       " 'heavy': 641,\n",
       " 'commercial': 642,\n",
       " 'sept': 643,\n",
       " 'potential': 644,\n",
       " 'governor': 645,\n",
       " 'working': 646,\n",
       " 'jumped': 647,\n",
       " 'special': 648,\n",
       " 'whose': 649,\n",
       " 'climbed': 650,\n",
       " 'construction': 651,\n",
       " 'meanwhile': 652,\n",
       " 'closing': 653,\n",
       " 'carter': 654,\n",
       " 'never': 655,\n",
       " 'student': 656,\n",
       " 'statistic': 657,\n",
       " 'chicago': 658,\n",
       " 'something': 659,\n",
       " 'started': 660,\n",
       " 'dividend': 661,\n",
       " 'ford': 662,\n",
       " 'california': 663,\n",
       " 'prime': 664,\n",
       " 'attack': 665,\n",
       " 'turned': 666,\n",
       " 'beginning': 667,\n",
       " 'agreed': 668,\n",
       " 'behind': 669,\n",
       " 'source': 670,\n",
       " 'morgan': 671,\n",
       " 'debate': 672,\n",
       " 'virginia': 673,\n",
       " 'really': 674,\n",
       " 'rest': 675,\n",
       " 'legislation': 676,\n",
       " 'jump': 677,\n",
       " 'paid': 678,\n",
       " 'george': 679,\n",
       " 'retirement': 680,\n",
       " 'trying': 681,\n",
       " 'predicted': 682,\n",
       " 'modest': 683,\n",
       " 'advanced': 684,\n",
       " 'german': 685,\n",
       " 'single': 686,\n",
       " 'cutting': 687,\n",
       " 'morning': 688,\n",
       " 'cause': 689,\n",
       " 'south': 690,\n",
       " 'drug': 691,\n",
       " 'kind': 692,\n",
       " 'borrowing': 693,\n",
       " 'posted': 694,\n",
       " 'signal': 695,\n",
       " 'holiday': 696,\n",
       " 'went': 697,\n",
       " 'straight': 698,\n",
       " 'huge': 699,\n",
       " 'trust': 700,\n",
       " 'journal': 701,\n",
       " 'producer': 702,\n",
       " 'done': 703,\n",
       " 'employer': 704,\n",
       " 'oct': 705,\n",
       " 'minute': 706,\n",
       " 'court': 707,\n",
       " 'worst': 708,\n",
       " 'officer': 709,\n",
       " 'different': 710,\n",
       " 'response': 711,\n",
       " 'utility': 712,\n",
       " 'maryland': 713,\n",
       " 'project': 714,\n",
       " 'airline': 715,\n",
       " 'asia': 716,\n",
       " 'changed': 717,\n",
       " 'slowing': 718,\n",
       " 'dealer': 719,\n",
       " 'package': 720,\n",
       " 'moved': 721,\n",
       " 'payroll': 722,\n",
       " 'gap': 723,\n",
       " 'add': 724,\n",
       " 'broker': 725,\n",
       " 'steady': 726,\n",
       " 'improvement': 727,\n",
       " 'largely': 728,\n",
       " 'active': 729,\n",
       " 'slump': 730,\n",
       " 'process': 731,\n",
       " 'able': 732,\n",
       " 'property': 733,\n",
       " 'quickly': 734,\n",
       " 'additional': 735,\n",
       " 'increasing': 736,\n",
       " 'manufacturer': 737,\n",
       " 'grew': 738,\n",
       " 'crash': 739,\n",
       " 'speech': 740,\n",
       " 'particularly': 741,\n",
       " 'sen': 742,\n",
       " 'book': 743,\n",
       " 'declining': 744,\n",
       " 'boom': 745,\n",
       " 'followed': 746,\n",
       " 'plant': 747,\n",
       " 'gdp': 748,\n",
       " 'shift': 749,\n",
       " 'break': 750,\n",
       " 'moving': 751,\n",
       " 'bit': 752,\n",
       " 'stimulus': 753,\n",
       " 'deposit': 754,\n",
       " 'sent': 755,\n",
       " 'serious': 756,\n",
       " 'bid': 757,\n",
       " 'try': 758,\n",
       " 'basis': 759,\n",
       " 'eight': 760,\n",
       " 'unchanged': 761,\n",
       " 'surplus': 762,\n",
       " 'continuing': 763,\n",
       " 'thought': 764,\n",
       " 'grow': 765,\n",
       " 'tech': 766,\n",
       " 'asked': 767,\n",
       " 'let': 768,\n",
       " 'available': 769,\n",
       " 'certain': 770,\n",
       " 'showing': 771,\n",
       " 'william': 772,\n",
       " 'germany': 773,\n",
       " 'worth': 774,\n",
       " 'similar': 775,\n",
       " 'focus': 776,\n",
       " 'relatively': 777,\n",
       " 'expert': 778,\n",
       " 'internet': 779,\n",
       " 'gas': 780,\n",
       " 'greater': 781,\n",
       " 'asian': 782,\n",
       " 'child': 783,\n",
       " 'word': 784,\n",
       " 'stronger': 785,\n",
       " 'weakness': 786,\n",
       " 'strategist': 787,\n",
       " 'pushed': 788,\n",
       " 'running': 789,\n",
       " 'common': 790,\n",
       " 'failed': 791,\n",
       " 'factory': 792,\n",
       " 'needed': 793,\n",
       " 'david': 794,\n",
       " 'seem': 795,\n",
       " 'opportunity': 796,\n",
       " 'moderate': 797,\n",
       " 'class': 798,\n",
       " 'role': 799,\n",
       " 'smaller': 800,\n",
       " 'tokyo': 801,\n",
       " 'warned': 802,\n",
       " 'name': 803,\n",
       " 'saying': 804,\n",
       " 'initial': 805,\n",
       " 'gave': 806,\n",
       " 'hurt': 807,\n",
       " 'estimated': 808,\n",
       " 'noted': 809,\n",
       " 'include': 810,\n",
       " 'texas': 811,\n",
       " 'household': 812,\n",
       " 'either': 813,\n",
       " 'military': 814,\n",
       " 'saw': 815,\n",
       " 'larger': 816,\n",
       " 'continues': 817,\n",
       " 'situation': 818,\n",
       " 'peak': 819,\n",
       " 'track': 820,\n",
       " 'bear': 821,\n",
       " 'light': 822,\n",
       " 'goal': 823,\n",
       " 'staff': 824,\n",
       " 'issued': 825,\n",
       " 'candidate': 826,\n",
       " 'education': 827,\n",
       " 'jan': 828,\n",
       " 'rail': 829,\n",
       " 'borrower': 830,\n",
       " 'revised': 831,\n",
       " 'using': 832,\n",
       " 'feel': 833,\n",
       " 'bring': 834,\n",
       " 'answer': 835,\n",
       " 'woman': 836,\n",
       " 'author': 837,\n",
       " 'drive': 838,\n",
       " 'benchmark': 839,\n",
       " 'analysis': 840,\n",
       " 'approved': 841,\n",
       " 'paper': 842,\n",
       " 'main': 843,\n",
       " 'expects': 844,\n",
       " 'paul': 845,\n",
       " 'volcker': 846,\n",
       " 'trouble': 847,\n",
       " 'consider': 848,\n",
       " 'series': 849,\n",
       " 'fuel': 850,\n",
       " 'size': 851,\n",
       " 'event': 852,\n",
       " 'faster': 853,\n",
       " 'nothing': 854,\n",
       " 'check': 855,\n",
       " 'majority': 856,\n",
       " 'th': 857,\n",
       " 'ap': 858,\n",
       " 'afternoon': 859,\n",
       " 'bureau': 860,\n",
       " 'spring': 861,\n",
       " 'fight': 862,\n",
       " 'chance': 863,\n",
       " 'upward': 864,\n",
       " 'related': 865,\n",
       " 'fallen': 866,\n",
       " 'review': 867,\n",
       " 'bet': 868,\n",
       " 'thus': 869,\n",
       " 'sure': 870,\n",
       " 'positive': 871,\n",
       " 'season': 872,\n",
       " 'accounting': 873,\n",
       " 'remained': 874,\n",
       " 'seek': 875,\n",
       " 'rebound': 876,\n",
       " 'presidential': 877,\n",
       " 'double': 878,\n",
       " 'paying': 879,\n",
       " 'tell': 880,\n",
       " 'organization': 881,\n",
       " 'giant': 882,\n",
       " 'reduced': 883,\n",
       " 'economics': 884,\n",
       " 'present': 885,\n",
       " 'offered': 886,\n",
       " 'weekend': 887,\n",
       " 'difficult': 888,\n",
       " 'reading': 889,\n",
       " 'whole': 890,\n",
       " 'investing': 891,\n",
       " 'actually': 892,\n",
       " 'pension': 893,\n",
       " 'page': 894,\n",
       " 'fast': 895,\n",
       " 'equipment': 896,\n",
       " 'regional': 897,\n",
       " 'negative': 898,\n",
       " 'worse': 899,\n",
       " 'ground': 900,\n",
       " 'london': 901,\n",
       " 'attention': 902,\n",
       " 'uncertainty': 903,\n",
       " 'direction': 904,\n",
       " 'man': 905,\n",
       " 'spokesman': 906,\n",
       " 'margin': 907,\n",
       " 'downturn': 908,\n",
       " 'financing': 909,\n",
       " 'stay': 910,\n",
       " 'minister': 911,\n",
       " 'appears': 912,\n",
       " 'always': 913,\n",
       " 'spend': 914,\n",
       " 'canadian': 915,\n",
       " 'easing': 916,\n",
       " 'conservative': 917,\n",
       " 'caused': 918,\n",
       " 'slide': 919,\n",
       " 'opening': 920,\n",
       " 'bankruptcy': 921,\n",
       " 'broader': 922,\n",
       " 'beyond': 923,\n",
       " 'attempt': 924,\n",
       " 'operating': 925,\n",
       " 'mexico': 926,\n",
       " 'suggests': 927,\n",
       " 'increasingly': 928,\n",
       " 'received': 929,\n",
       " 'warning': 930,\n",
       " 'allow': 931,\n",
       " 'everything': 932,\n",
       " 'hedge': 933,\n",
       " 'perhaps': 934,\n",
       " 'suggest': 935,\n",
       " 'finished': 936,\n",
       " 'client': 937,\n",
       " 'nixon': 938,\n",
       " 'canada': 939,\n",
       " 'james': 940,\n",
       " 'voter': 941,\n",
       " 'mostly': 942,\n",
       " 'chinese': 943,\n",
       " 'night': 944,\n",
       " 'flat': 945,\n",
       " 'interview': 946,\n",
       " 'sense': 947,\n",
       " 'corporation': 948,\n",
       " 'age': 949,\n",
       " 'inventory': 950,\n",
       " 'reach': 951,\n",
       " 'cap': 952,\n",
       " 'closely': 953,\n",
       " 'partner': 954,\n",
       " 'soared': 955,\n",
       " 'easy': 956,\n",
       " 'weekly': 957,\n",
       " 'dec': 958,\n",
       " 'taxpayer': 959,\n",
       " 'practice': 960,\n",
       " 'story': 961,\n",
       " 'suggested': 962,\n",
       " 'lawmaker': 963,\n",
       " 'associated': 964,\n",
       " 'brought': 965,\n",
       " 'quarterly': 966,\n",
       " 'boston': 967,\n",
       " 'person': 968,\n",
       " 'emerging': 969,\n",
       " 'men': 970,\n",
       " 'rating': 971,\n",
       " 'leave': 972,\n",
       " 'picture': 973,\n",
       " 'farm': 974,\n",
       " 'quality': 975,\n",
       " 'passed': 976,\n",
       " 'inflationary': 977,\n",
       " 'climb': 978,\n",
       " 'wide': 979,\n",
       " 'difference': 980,\n",
       " 'transaction': 981,\n",
       " 'addition': 982,\n",
       " 'widely': 983,\n",
       " 'pushing': 984,\n",
       " 'north': 985,\n",
       " 'create': 986,\n",
       " 'save': 987,\n",
       " 'indeed': 988,\n",
       " 'outside': 989,\n",
       " 'starting': 990,\n",
       " 'competition': 991,\n",
       " 'aug': 992,\n",
       " 'anti': 993,\n",
       " 'nine': 994,\n",
       " 'brokerage': 995,\n",
       " 'crude': 996,\n",
       " 'room': 997,\n",
       " 'release': 998,\n",
       " 'kept': 999,\n",
       " 'expense': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8bc0b15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8bc0b15",
    "outputId": "bc0c8ab2-9e8f-470d-a17e-89b96cd00afd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36554"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c30d7",
   "metadata": {
    "id": "016c30d7"
   },
   "source": [
    "### Padding Sequences\n",
    "Sentences and sequences tend to have different lengths, however our model is expecting equally sized observations.\n",
    "Here we want to convert our texts to sequences and make them of the same length (in general, the lenght of the longest of our sequences). We are going to use here `pad_sequences` from Tensorflow (documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences)), to add zeroes to the tokenized sentences until they all reach the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea518a6d",
   "metadata": {
    "id": "ea518a6d"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(wtxt_train)\n",
    "padded_sequences = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a3a19b1",
   "metadata": {
    "id": "6a3a19b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[186,\n",
       " 2146,\n",
       " 88,\n",
       " 346,\n",
       " 19,\n",
       " 6,\n",
       " 33,\n",
       " 186,\n",
       " 2559,\n",
       " 754,\n",
       " 886,\n",
       " 147,\n",
       " 10,\n",
       " 373,\n",
       " 2943,\n",
       " 370,\n",
       " 25,\n",
       " 346,\n",
       " 19,\n",
       " 1464,\n",
       " 508,\n",
       " 86,\n",
       " 156,\n",
       " 75,\n",
       " 13,\n",
       " 4,\n",
       " 193,\n",
       " 7949,\n",
       " 63,\n",
       " 2146,\n",
       " 565,\n",
       " 1687,\n",
       " 10,\n",
       " 44,\n",
       " 186,\n",
       " 293,\n",
       " 16,\n",
       " 754,\n",
       " 88,\n",
       " 19,\n",
       " 321,\n",
       " 39,\n",
       " 133,\n",
       " 10,\n",
       " 349,\n",
       " 9914,\n",
       " 54,\n",
       " 2,\n",
       " 7950,\n",
       " 3269,\n",
       " 631,\n",
       " 128,\n",
       " 94,\n",
       " 16,\n",
       " 63,\n",
       " 754,\n",
       " 44,\n",
       " 186,\n",
       " 1935,\n",
       " 19,\n",
       " 133,\n",
       " 9914,\n",
       " 46,\n",
       " 10,\n",
       " 9914,\n",
       " 349,\n",
       " 3807,\n",
       " 6,\n",
       " 33,\n",
       " 9114,\n",
       " 2470,\n",
       " 879,\n",
       " 139,\n",
       " 21385,\n",
       " 193,\n",
       " 7949,\n",
       " 2146,\n",
       " 86,\n",
       " 1234,\n",
       " 800,\n",
       " 247,\n",
       " 1,\n",
       " 63,\n",
       " 2146,\n",
       " 1379,\n",
       " 9914,\n",
       " 3,\n",
       " 186,\n",
       " 94,\n",
       " 16,\n",
       " 293,\n",
       " 16,\n",
       " 77,\n",
       " 146,\n",
       " 565,\n",
       " 289,\n",
       " 1110,\n",
       " 2442,\n",
       " 1335,\n",
       " 370,\n",
       " 25,\n",
       " 381,\n",
       " 19,\n",
       " 2615]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf5a3374",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf5a3374",
    "outputId": "99253544-bbca-48ca-e1d5-b86689138957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  381,   19, 2615],\n",
       "       [   0,    0,    0, ...,  157,   49,  178],\n",
       "       [   0,    0,    0, ...,   10,   83,   43],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  514,  527,  120],\n",
       "       [   0,    0,    0, ...,  278,  103,   59],\n",
       "       [   0,    0,    0, ...,   41,  184,   22]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89dd0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pad_seq'] = padded_sequences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f444fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>pad_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     relevance                                            pad_seq\n",
       "0            1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1            0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2            0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3            0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4            1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "...        ...                                                ...\n",
       "7995         1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "7996         0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "7997         0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "7998         0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "7999         0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['whole_txt'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "561a6b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>whole_txt</th>\n",
       "      <th>pad_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[yield, cd, fell, latest, week, new, york, yie...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[morning, brief, white, house, seek, limit, ch...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[banking, bill, negotiator, set, compromise, p...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[manager, journal, sniffing, drug, abuser, qui...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[currency, trading, dollar, remains, tight, ra...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relevance                                          whole_txt  \\\n",
       "0         1  [yield, cd, fell, latest, week, new, york, yie...   \n",
       "1         0  [morning, brief, white, house, seek, limit, ch...   \n",
       "2         0  [banking, bill, negotiator, set, compromise, p...   \n",
       "3         0  [manager, journal, sniffing, drug, abuser, qui...   \n",
       "4         1  [currency, trading, dollar, remains, tight, ra...   \n",
       "\n",
       "                                             pad_seq  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83826301",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f00e30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_sequences\n",
    "y = df['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fB_vM2GQkf-Y",
   "metadata": {
    "id": "fB_vM2GQkf-Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e0850ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19ab3a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  480,   22,  152],\n",
       "       [   0,    0,    0, ..., 1345, 2223,  129],\n",
       "       [   0,    0,    0, ...,  105, 2828,    3],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   36, 1930,    2],\n",
       "       [   0,    0,    0, ...,    5,   98,  353],\n",
       "       [   0,    0,    0, ...,   20,    1,  201]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d51f8bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120, 475)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f8059d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617     0\n",
       "2290    0\n",
       "4289    0\n",
       "1264    0\n",
       "2143    0\n",
       "       ..\n",
       "6140    0\n",
       "4170    0\n",
       "1761    0\n",
       "1252    0\n",
       "2155    0\n",
       "Name: relevance, Length: 5120, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "128bd1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adde4bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa0a8eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f0eab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35c078ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')\n",
    "y_val = y_val.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8e8b2",
   "metadata": {
    "id": "0fe8e8b2"
   },
   "source": [
    "### Building the model\n",
    "\n",
    "We are going to build a simple model that includes:\n",
    "- `Embedding` layer with an output representation of each word as a vector of dim 16\n",
    "- `LSTM` (see class slides for more detail or RNNs example notebook for more details) with an intermediate state of 100\n",
    "- An output layer `Dense` that connects the output of the LSTM and creates an output of 3 positions (one per class) as output of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9223fed7",
   "metadata": {},
   "source": [
    "That is model nr.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84e1fd75",
   "metadata": {
    "id": "84e1fd75"
   },
   "outputs": [],
   "source": [
    "# We are going to build our model with the Sequential API\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words,      # number of words to process as input\n",
    "                    100,    # output representation\n",
    "                    input_length=len(padded_sequences[0])))    # total length of each observation\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Change activation based on the number of classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "286e1067",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "286e1067",
    "outputId": "ef815e79-2cdb-4372-f0f2-a45738a6bd09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8000, 1), dtype=float32, numpy=\n",
       "array([[0.49327475],\n",
       "       [0.5015954 ],\n",
       "       [0.5079206 ],\n",
       "       ...,\n",
       "       [0.49665824],\n",
       "       [0.4952108 ],\n",
       "       [0.50029707]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "290f727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 475, 100)          3655400   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3735901 (14.25 MB)\n",
      "Trainable params: 3735901 (14.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101ccfc",
   "metadata": {
    "id": "1101ccfc"
   },
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55429b96",
   "metadata": {},
   "source": [
    "### MODEL 1 (The base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "826df8ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "826df8ad",
    "outputId": "954999b9-e6f3-43a2-dc81-a5c10a8e6ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "160/160 [==============================] - 64s 398ms/step - loss: 0.1545 - accuracy: 0.9412 - val_loss: 0.7135 - val_accuracy: 0.7867\n",
      "Epoch 2/3\n",
      "160/160 [==============================] - 63s 393ms/step - loss: 0.0632 - accuracy: 0.9781 - val_loss: 0.8994 - val_accuracy: 0.7680\n",
      "Epoch 3/3\n",
      "160/160 [==============================] - 60s 376ms/step - loss: 0.0429 - accuracy: 0.9865 - val_loss: 0.9178 - val_accuracy: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ce24935cd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=3, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1484a19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1484a19",
    "outputId": "5db7ef87-e57e-4f8c-c74b-f124fab03672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(model(padded_sequences).numpy().argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781be31e",
   "metadata": {},
   "source": [
    "Model 1 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76c6df0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 139ms/step - loss: 0.8972 - accuracy: 0.7731\n",
      "Test Loss: 0.8972\n",
      "Test Accuracy: 77.31%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3526a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 130ms/step\n"
     ]
    }
   ],
   "source": [
    "#Prection and Confusion Matrix\n",
    "y_pred = model.predict(X_test)\n",
    "bin_y_pred = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "062c9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_y_pred = np.squeeze(bin_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23edf0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f682ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e345456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1170,  133],\n",
       "       [ 230,   67]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, bin_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5437a9f",
   "metadata": {},
   "source": [
    "### MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e790349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to build our model with the Sequential API\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Embedding(total_words,      # number of words to process as input\n",
    "                    50,    # output representation\n",
    "                    input_length=len(padded_sequences[0])))    # total length of each observation\n",
    "\n",
    "model2.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4fded32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 475, 50)           1827700   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1847951 (7.05 MB)\n",
      "Trainable params: 1847951 (7.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db80d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cc28f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160/160 [==============================] - 32s 179ms/step - loss: 0.4856 - accuracy: 0.8174 - val_loss: 0.4387 - val_accuracy: 0.8305\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 33s 207ms/step - loss: 0.3536 - accuracy: 0.8463 - val_loss: 0.4927 - val_accuracy: 0.8086\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 27s 169ms/step - loss: 0.2008 - accuracy: 0.9189 - val_loss: 0.6510 - val_accuracy: 0.7852\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 26s 163ms/step - loss: 0.1024 - accuracy: 0.9639 - val_loss: 0.8369 - val_accuracy: 0.7570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ce281b4c10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=5, validation_data = (X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a59b099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 4s 76ms/step - loss: 0.4429 - accuracy: 0.8119\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c8e04a",
   "metadata": {},
   "source": [
    "### MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cce897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(total_words,      # number of words to process as input\n",
    "                    100,    # output representation\n",
    "                    input_length=len(padded_sequences[0])))    # total length of each observation\n",
    "\n",
    "model3.add(LSTM(100, return_sequences=False))\n",
    "\n",
    "model3.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model3.compile(optimizer='adam', loss='hinge', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a14b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 475, 100)          3655400   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3735901 (14.25 MB)\n",
      "Trainable params: 3735901 (14.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6963b196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160/160 [==============================] - 73s 438ms/step - loss: 1.0227 - accuracy: 0.8188 - val_loss: 1.0000 - val_accuracy: 0.8305\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 64s 398ms/step - loss: 1.0000 - accuracy: 0.8213 - val_loss: 1.0000 - val_accuracy: 0.8305\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 64s 401ms/step - loss: 1.0000 - accuracy: 0.8213 - val_loss: 1.0000 - val_accuracy: 0.8305\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 65s 407ms/step - loss: 1.0000 - accuracy: 0.8213 - val_loss: 1.0000 - val_accuracy: 0.8305\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 64s 399ms/step - loss: 1.0000 - accuracy: 0.8213 - val_loss: 1.0000 - val_accuracy: 0.8305\n"
     ]
    }
   ],
   "source": [
    "his = model3.fit(X_train, y_train, epochs=5, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67912764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.0227415561676025,\n",
       "  1.0000214576721191,\n",
       "  1.0000132322311401,\n",
       "  1.0000085830688477,\n",
       "  1.000005841255188],\n",
       " 'accuracy': [0.8187500238418579,\n",
       "  0.8212890625,\n",
       "  0.8212890625,\n",
       "  0.8212890625,\n",
       "  0.8212890625],\n",
       " 'val_loss': [1.00003182888031,\n",
       "  1.000016212463379,\n",
       "  1.000010371208191,\n",
       "  1.0000072717666626,\n",
       "  1.0000053644180298],\n",
       " 'val_accuracy': [0.8304687738418579,\n",
       "  0.8304687738418579,\n",
       "  0.8304687738418579,\n",
       "  0.8304687738418579,\n",
       "  0.8304687738418579]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "218f1b11",
   "metadata": {
    "id": "218f1b11"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a49a0850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ce1611c0a0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(his.history['loss'])\n",
    "plt.plot(his.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c7755",
   "metadata": {},
   "source": [
    "### MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38ed8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Embedding(total_words,      # number of words to process as input\n",
    "                    100,    # output representation\n",
    "                    input_length=len(padded_sequences[0])))    # total length of each observation\n",
    "\n",
    "model4.add(LSTM(100, return_sequences=False))\n",
    "\n",
    "model4.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model4.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d97c51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 475, 100)          3655400   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3735901 (14.25 MB)\n",
      "Trainable params: 3735901 (14.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7fba69cf",
   "metadata": {
    "id": "7fba69cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "160/160 [==============================] - 66s 397ms/step - loss: 0.5507 - accuracy: 0.8193 - val_loss: 0.4704 - val_accuracy: 0.8305\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 58s 364ms/step - loss: 0.4724 - accuracy: 0.8213 - val_loss: 0.4560 - val_accuracy: 0.8305\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 61s 381ms/step - loss: 0.4697 - accuracy: 0.8213 - val_loss: 0.4553 - val_accuracy: 0.8305\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 63s 392ms/step - loss: 0.4695 - accuracy: 0.8213 - val_loss: 0.4551 - val_accuracy: 0.8305\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 65s 404ms/step - loss: 0.4695 - accuracy: 0.8213 - val_loss: 0.4557 - val_accuracy: 0.8305\n"
     ]
    }
   ],
   "source": [
    "his2 = model4.fit(X_train, y_train, epochs=5, validation_data = (X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
