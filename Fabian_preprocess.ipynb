{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   _unit_id               8000 non-null   int64  \n",
      " 1   _golden                8000 non-null   bool   \n",
      " 2   _unit_state            8000 non-null   object \n",
      " 3   _trusted_judgments     8000 non-null   int64  \n",
      " 4   _last_judgment_at      8000 non-null   object \n",
      " 5   positivity             1420 non-null   float64\n",
      " 6   positivity:confidence  3775 non-null   float64\n",
      " 7   relevance              8000 non-null   object \n",
      " 8   relevance:confidence   8000 non-null   float64\n",
      " 9   articleid              8000 non-null   object \n",
      " 10  date                   8000 non-null   object \n",
      " 11  headline               8000 non-null   object \n",
      " 12  positivity_gold        0 non-null      float64\n",
      " 13  relevance_gold         0 non-null      float64\n",
      " 14  text                   8000 non-null   object \n",
      "dtypes: bool(1), float64(5), int64(2), object(7)\n",
      "memory usage: 882.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('US-Economic-News.csv', delimiter=',', encoding= 'ISO-8859-1')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>positivity</th>\n",
       "      <th>positivity:confidence</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance:confidence</th>\n",
       "      <th>articleid</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>positivity_gold</th>\n",
       "      <th>relevance_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842613455</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398217788</td>\n",
       "      <td>8/14/91</td>\n",
       "      <td>Yields on CDs Fell in the Latest Week</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842613456</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 16:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_399019502</td>\n",
       "      <td>8/21/07</td>\n",
       "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Wall Street Journal Online&lt;/br&gt;&lt;/br&gt;The Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842613457</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 1:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_398284048</td>\n",
       "      <td>11/14/91</td>\n",
       "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>842613458</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 2:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.675</td>\n",
       "      <td>wsj_397959018</td>\n",
       "      <td>6/16/86</td>\n",
       "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>842613459</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398838054</td>\n",
       "      <td>10/4/02</td>\n",
       "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  842613455    False   finalized                   3     12/5/15 17:48   \n",
       "1  842613456    False   finalized                   3     12/5/15 16:54   \n",
       "2  842613457    False   finalized                   3      12/5/15 1:59   \n",
       "3  842613458    False   finalized                   3      12/5/15 2:19   \n",
       "4  842613459    False   finalized                   3     12/5/15 17:48   \n",
       "\n",
       "   positivity  positivity:confidence relevance  relevance:confidence  \\\n",
       "0         3.0                 0.6400       yes                 0.640   \n",
       "1         NaN                    NaN        no                 1.000   \n",
       "2         NaN                    NaN        no                 1.000   \n",
       "3         NaN                 0.0000        no                 0.675   \n",
       "4         3.0                 0.3257       yes                 0.640   \n",
       "\n",
       "       articleid      date                                           headline  \\\n",
       "0  wsj_398217788   8/14/91              Yields on CDs Fell in the Latest Week   \n",
       "1  wsj_399019502   8/21/07  The Morning Brief: White House Seeks to Limit ...   \n",
       "2  wsj_398284048  11/14/91  Banking Bill Negotiators Set Compromise --- Pl...   \n",
       "3  wsj_397959018   6/16/86  Manager's Journal: Sniffing Out Drug Abusers I...   \n",
       "4  wsj_398838054   10/4/02  Currency Trading: Dollar Remains in Tight Rang...   \n",
       "\n",
       "   positivity_gold  relevance_gold  \\\n",
       "0              NaN             NaN   \n",
       "1              NaN             NaN   \n",
       "2              NaN             NaN   \n",
       "3              NaN             NaN   \n",
       "4              NaN             NaN   \n",
       "\n",
       "                                                text  \n",
       "0  NEW YORK -- Yields on most certificates of dep...  \n",
       "1  The Wall Street Journal Online</br></br>The Mo...  \n",
       "2  WASHINGTON -- In an effort to achieve banking ...  \n",
       "3  The statistics on the enormous costs of employ...  \n",
       "4  NEW YORK -- Indecision marked the dollar's ton...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tengo que agarrar y cambiar los dtype de las variables con encoding\n",
    "# drop positivity gold and relevance gold\n",
    "# positivity and ::confidence, have very sparse values\n",
    "# _unit_state has only the finalized observation and golden the False observation, and trusted judgments only observation '3'\n",
    "\n",
    "df = df.drop(columns = ['_unit_id', 'positivity_gold', 'relevance_gold', '_unit_state', '_golden', '_trusted_judgments',\n",
    "                         '_unit_state', '_last_judgment_at', 'positivity', 'positivity:confidence', 'relevance:confidence', 'articleid',\n",
    "                       'date'], axis = 1)\n",
    "\n",
    "#df['articleid'] = df['articleid'].str.slice(0, 3)\n",
    "# so far, these variables SHOULD be dropped for sure as well as unit id and article id\n",
    "# should discuss between the positivity and positivity confidence due to amount of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# filtered_df = df[df['relevance'] == 'yes']\n",
    "\n",
    "# filtered_df['articleid'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>Yields on CDs Fell in the Latest Week</td>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
       "      <td>The Wall Street Journal Online&lt;/br&gt;&lt;/br&gt;The Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relevance                                           headline  \\\n",
       "0       yes              Yields on CDs Fell in the Latest Week   \n",
       "1        no  The Morning Brief: White House Seeks to Limit ...   \n",
       "2        no  Banking Bill Negotiators Set Compromise --- Pl...   \n",
       "3        no  Manager's Journal: Sniffing Out Drug Abusers I...   \n",
       "4       yes  Currency Trading: Dollar Remains in Tight Rang...   \n",
       "\n",
       "                                                text  \n",
       "0  NEW YORK -- Yields on most certificates of dep...  \n",
       "1  The Wall Street Journal Online</br></br>The Mo...  \n",
       "2  WASHINGTON -- In an effort to achieve banking ...  \n",
       "3  The statistics on the enormous costs of employ...  \n",
       "4  NEW YORK -- Indecision marked the dollar's ton...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.10.3-cp39-cp39-win_amd64.whl (269 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\majon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\majon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\majon\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2023.10.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\majon\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\majon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\majon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\majon\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Ensure you have downloaded the necessary NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['whole_txt'] = df['headline']+ ' ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtxt_train = np.array(df['whole_txt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wtxt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wtxt_train)):\n",
    "    # Deletion of non-latin alfabet signs, also numbers\n",
    "    wtxt_train[i] = re.sub(r'[^a-zA-Z]', ' ', wtxt_train[i])\n",
    "    # Removing single letter works like 'a'.\n",
    "    wtxt_train[i] = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', wtxt_train[i])\n",
    "    # Removing double spaces\n",
    "    wtxt_train[i] = re.sub(r'\\s+', ' ', wtxt_train[i])\n",
    "    # Lower case\n",
    "    wtxt_train[i] = wtxt_train[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wtxt_train)):\n",
    "    wtxt_train[i] = word_tokenize(wtxt_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(wtxt_train)):\n",
    "    wtxt_train[i] = [word for word in wtxt_train[i] if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yields',\n",
       " 'cds',\n",
       " 'fell',\n",
       " 'latest',\n",
       " 'week',\n",
       " 'new',\n",
       " 'york',\n",
       " 'yields',\n",
       " 'certificates',\n",
       " 'deposit',\n",
       " 'offered',\n",
       " 'major',\n",
       " 'banks',\n",
       " 'dropped',\n",
       " 'tenth',\n",
       " 'percentage',\n",
       " 'point',\n",
       " 'latest',\n",
       " 'week',\n",
       " 'reflecting',\n",
       " 'overall',\n",
       " 'decline',\n",
       " 'short',\n",
       " 'term',\n",
       " 'interest',\n",
       " 'rates',\n",
       " 'br',\n",
       " 'br',\n",
       " 'small',\n",
       " 'denomination',\n",
       " 'consumer',\n",
       " 'cds',\n",
       " 'sold',\n",
       " 'directly',\n",
       " 'banks',\n",
       " 'average',\n",
       " 'yield',\n",
       " 'six',\n",
       " 'month',\n",
       " 'deposits',\n",
       " 'fell',\n",
       " 'week',\n",
       " 'ended',\n",
       " 'yesterday',\n",
       " 'according',\n",
       " 'bank',\n",
       " 'survey',\n",
       " 'banxquote',\n",
       " 'money',\n",
       " 'markets',\n",
       " 'wilmington',\n",
       " 'del',\n",
       " 'information',\n",
       " 'service',\n",
       " 'br',\n",
       " 'br',\n",
       " 'three',\n",
       " 'month',\n",
       " 'consumer',\n",
       " 'deposits',\n",
       " 'average',\n",
       " 'yield',\n",
       " 'sank',\n",
       " 'week',\n",
       " 'according',\n",
       " 'banxquote',\n",
       " 'two',\n",
       " 'banks',\n",
       " 'banxquote',\n",
       " 'survey',\n",
       " 'citibank',\n",
       " 'new',\n",
       " 'york',\n",
       " 'corestates',\n",
       " 'pennsylvania',\n",
       " 'paying',\n",
       " 'less',\n",
       " 'threemonth',\n",
       " 'small',\n",
       " 'denomination',\n",
       " 'cds',\n",
       " 'br',\n",
       " 'br',\n",
       " 'declines',\n",
       " 'somewhat',\n",
       " 'smaller',\n",
       " 'five',\n",
       " 'year',\n",
       " 'consumer',\n",
       " 'cds',\n",
       " 'eased',\n",
       " 'banxquote',\n",
       " 'said',\n",
       " 'br',\n",
       " 'br',\n",
       " 'yields',\n",
       " 'three',\n",
       " 'month',\n",
       " 'six',\n",
       " 'month',\n",
       " 'treasury',\n",
       " 'bills',\n",
       " 'sold',\n",
       " 'monday',\n",
       " 'auction',\n",
       " 'plummeted',\n",
       " 'fifth',\n",
       " 'percentage',\n",
       " 'point',\n",
       " 'previous',\n",
       " 'week',\n",
       " 'respectively']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtxt_train[0]\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(wtxt_train)):\n",
    "    wtxt_train[i] = [lemmatizer.lemmatize(word) for word in wtxt_train[i]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['whole_txt'] = wtxt_train\n",
    "df = df.drop(['headline', 'text'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>whole_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>[yield, cd, fell, latest, week, new, york, yie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>[morning, brief, white, house, seek, limit, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>[banking, bill, negotiator, set, compromise, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>[manager, journal, sniffing, drug, abuser, qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>[currency, trading, dollar, remains, tight, ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  relevance                                          whole_txt\n",
       "0       yes  [yield, cd, fell, latest, week, new, york, yie...\n",
       "1        no  [morning, brief, white, house, seek, limit, ch...\n",
       "2        no  [banking, bill, negotiator, set, compromise, p...\n",
       "3        no  [manager, journal, sniffing, drug, abuser, qui...\n",
       "4       yes  [currency, trading, dollar, remains, tight, ra..."
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['relevance'], axis = 1)\n",
    "y = df['relevance']\n",
    "\n",
    "# here stratify is used to balance dataset as much as possible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>[trade, deficit, worry, nearly, halt, activity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>[tea, party, activist, complicate, republican,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6716</th>\n",
       "      <td>[elder, share, one, great, feat, social, engin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              whole_txt\n",
       "420   [trade, deficit, worry, nearly, halt, activity...\n",
       "3350  [tea, party, activist, complicate, republican,...\n",
       "6716  [elder, share, one, great, feat, social, engin..."
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420      no\n",
       "3350     no\n",
       "6716    yes\n",
       "Name: relevance, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "word2vec_model = gensim.models.Word2Vec(X_train['whole_txt'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # Remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.index_to_key]\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "\n",
    "# Vectorize each column in training and test sets\n",
    "X_train['vectorized_text'] = [document_vector(word2vec_model, doc) for doc in X_train['whole_txt']]\n",
    "\n",
    "X_test['vectorized_text'] = [document_vector(word2vec_model, doc) for doc in X_test['whole_txt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_txt</th>\n",
       "      <th>vectorized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>[growing, respect, need, personnel, area, rela...</td>\n",
       "      <td>[-0.11448828, 0.16956037, 0.48502818, 0.148715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>[fed, chief, signal, rate, cut, authoraffiliat...</td>\n",
       "      <td>[-0.16014144, 0.35196736, 0.6381882, 0.2047706...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059</th>\n",
       "      <td>[smorgasbord, mortgage, signed, contract, buy,...</td>\n",
       "      <td>[-0.531506, 0.28280517, 0.29646155, 0.3589064,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5880</th>\n",
       "      <td>[digest, cisco, system, make, internet, equipm...</td>\n",
       "      <td>[-0.031654067, -0.25615236, 0.29563683, 0.3256...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>[president, vacation, marred, worry, renewed, ...</td>\n",
       "      <td>[0.122463286, 0.34133253, 0.46179217, 0.192661...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              whole_txt  \\\n",
       "6006  [growing, respect, need, personnel, area, rela...   \n",
       "2304  [fed, chief, signal, rate, cut, authoraffiliat...   \n",
       "7059  [smorgasbord, mortgage, signed, contract, buy,...   \n",
       "5880  [digest, cisco, system, make, internet, equipm...   \n",
       "6700  [president, vacation, marred, worry, renewed, ...   \n",
       "\n",
       "                                        vectorized_text  \n",
       "6006  [-0.11448828, 0.16956037, 0.48502818, 0.148715...  \n",
       "2304  [-0.16014144, 0.35196736, 0.6381882, 0.2047706...  \n",
       "7059  [-0.531506, 0.28280517, 0.29646155, 0.3589064,...  \n",
       "5880  [-0.031654067, -0.25615236, 0.29563683, 0.3256...  \n",
       "6700  [0.122463286, 0.34133253, 0.46179217, 0.192661...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac73f219ecb0e616815df33a5f0d272ef4060a3ce258f788ec56e0f80c4efd9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
